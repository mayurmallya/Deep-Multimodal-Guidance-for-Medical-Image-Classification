{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality ['t1', 't2', 't1ce', 'flair']\n",
    "modality = 'flair'\n",
    "\n",
    "# Fold \n",
    "fold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8612add",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_folder = '/path/to/rad/features'\n",
    "g_rad_folder = '/path/to/guided/rad/features/'\n",
    "label_folder = '/path/to/labels/'\n",
    "results_dir = '/path/to/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e5594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d21715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e529416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidanceBoth_dataset(Dataset):\n",
    "    def __init__(self, rad_folder, g_rad_folder, label_folder, modality, fold, datasplit):\n",
    "        \n",
    "        self.rad_array = np.load(os.path.join(rad_folder, modality, str(fold), datasplit+'_'+str(fold)+'_'+modality+'.npy'))\n",
    "        self.g_rad_array = np.load(os.path.join(g_rad_folder, modality, modality+'_'+str(fold)+'_'+datasplit+'.npy'))\n",
    "        \n",
    "        label_csv = pd.read_csv(os.path.join(label_folder, 'split_'+str(fold)+'_'+datasplit+'.csv'))\n",
    "        label_list = label_csv['class'].tolist()\n",
    "        label_dict = {'G':0, 'O':1, 'A':2}\n",
    "        self.labels = [label_dict[i] for i in label_list]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.rad_array) == len(self.g_rad_array)\n",
    "        assert len(self.rad_array) == len(self.labels)\n",
    "        return len(self.rad_array)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        r = self.rad_array[idx]\n",
    "        gr = self.g_rad_array[idx]\n",
    "        c = np.concatenate([gr, r])\n",
    "        label = self.labels[idx]\n",
    "        data = {'input':c, 'label':label}\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01426a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = GuidanceBoth_dataset(rad_folder, g_rad_folder, label_folder, modality, fold, 'train')\n",
    "val_set = GuidanceBoth_dataset(rad_folder, g_rad_folder, label_folder, modality, fold, 'val')\n",
    "test_set = GuidanceBoth_dataset(rad_folder, g_rad_folder, label_folder, modality, fold, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted random sampler\n",
    "label_dict = {'G':0, 'O':1, 'A':2}\n",
    "csv_file = os.path.join(label_folder, 'split_'+str(fold)+'_'+'train.csv')\n",
    "df = pd.read_csv(csv_file, usecols=['class'])\n",
    "y_train = df['class']\n",
    "labels = [label_dict[t] for t in y_train]\n",
    "labels = np.array(labels)\n",
    "class_sample_count = np.array([len(np.where(labels==t)[0]) for t in np.unique(labels)]) # np.unique returns sorted unique values\n",
    "class_sample_probabilities = 1./class_sample_count\n",
    "sample_probabilities = np.array([class_sample_probabilities[t] for t in labels])\n",
    "sample_probabilities = torch.from_numpy(sample_probabilities)\n",
    "wrs = WeightedRandomSampler(weights = sample_probabilities.type('torch.DoubleTensor'), num_samples = len(sample_probabilities), replacement = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc3da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=50, sampler=wrs)\n",
    "val_loader = DataLoader(val_set, batch_size=30, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=30, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ec316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidanceBoth_architecture(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GuidanceBoth_architecture, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(in_features=1536, out_features=50)\n",
    "        self.l2 = nn.Linear(in_features=50, out_features=3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "model = GuidanceBoth_architecture()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb81379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd06f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cded444",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = torch.tensor([1., 1.7, 1.62]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=loss_weights)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-6, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=20, stop_epoch=50, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 20\n",
    "            stop_epoch (int): Earliest epoch possible for stopping\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.stop_epoch = stop_epoch\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, epoch, val_loss, model, ckpt_name = 'checkpoint.pt'):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, ckpt_name)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience and epoch > self.stop_epoch:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, ckpt_name)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, ckpt_name):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), ckpt_name)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "# early_stopping = False\n",
    "early_stopping = EarlyStopping(patience=200, stop_epoch=100, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bdf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_train_loss = 0.0\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        c, label = data['input'], data['label']\n",
    "        c, label = c.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(c)\n",
    "        loss_train = criterion(pred, label)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss_train.item()\n",
    "\n",
    "    loss_train_avg = running_train_loss/len(train_loader)\n",
    "    train_loss.append(loss_train_avg)\n",
    "    print('Epoch {} of {}, Train Loss: {:.3f}'.format(epoch+1, epochs, loss_train_avg))\n",
    "    \n",
    "    running_val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            c, label = data['input'], data['label']\n",
    "            c, label = c.to(device), label.to(device)\n",
    "            pred = model(c)\n",
    "            loss_val = criterion(pred, label)\n",
    "            running_val_loss += loss_val.item()\n",
    "            \n",
    "        loss_val_avg = running_val_loss/len(val_loader)\n",
    "        val_loss.append(loss_val_avg)\n",
    "        \n",
    "    if early_stopping:\n",
    "        early_stopping(epoch, loss_val_avg, model, ckpt_name=os.path.join(results_dir, 'guided_'+modality+'_'+str(fold)+'.pt'))\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbef223",
   "metadata": {},
   "outputs": [],
   "source": [
    "if early_stopping:\n",
    "    model.load_state_dict(torch.load(os.path.join(results_dir, 'guided_'+modality+'_'+str(fold)+'.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='train_loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the network \n",
    "\n",
    "test_loss = []\n",
    "running_test_loss = 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        c, label = data['input'], data['label']\n",
    "        c, label = c.to(device), label.to(device)\n",
    "        pred = model(c)\n",
    "        predict = torch.argmax(pred, dim=1)\n",
    "        loss_test = criterion(pred, label)\n",
    "        running_test_loss += loss_test.item()\n",
    "\n",
    "    loss_test_avg = running_test_loss/len(test_loader)\n",
    "    test_loss.append(loss_test_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b880b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = metrics.balanced_accuracy_score(label.cpu().numpy(), predict.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cedf1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f34ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
